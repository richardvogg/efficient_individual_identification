{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.transforms import Resize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as Func\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070aab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', type=str, default=\"/usr/users/vogg/Labelling/Lemurs/labelling_app_indID/experiments/\")\n",
    "parser.add_argument('--output_path', type=str, default=\"models/id/\")\n",
    "parser.add_argument('--experiment', type=str, default=\"cluster_1000_5000\")\n",
    "parser.add_argument('--group', type=str, default=\"R1\")\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--gpus', type=int, nargs='+', default=[0])\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9239229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDDataset(Dataset):\n",
    "    def __init__(self, root_path, txt_filename='cluster_1000_5000_R1.txt', train=True, transform=None, test_size=0.2, unknown_prop = 1, random_state=64):\n",
    "        self.root_path = root_path\n",
    "        self.image_dir = os.path.join(root_path, \"images\")\n",
    "        self.txt_path = os.path.join(root_path, txt_filename)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Read label file\n",
    "        df = pd.read_csv(self.txt_path, header=None,\n",
    "                         names=[\"filename\", \"x\", \"y\", \"w\", \"h\", \"id\", \"score\"])\n",
    "\n",
    "        # Extract experiment name for splitting (e.g. \"R_e1_c1\" from \"R_e1_c1_31257.png\")\n",
    "        df[\"experiment\"] = df[\"filename\"].apply(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n",
    "\n",
    "        if 0 < unknown_prop < 1:\n",
    "            max_id = df[\"id\"].max()\n",
    "            max_id_rows = df[df[\"id\"] == max_id]\n",
    "            sampled_max_id_rows = max_id_rows.sample(frac=unknown_prop, random_state=random_state)\n",
    "            df = pd.concat([df[df[\"id\"] != max_id], sampled_max_id_rows]).reset_index(drop=True)\n",
    "\n",
    "        # Split by experiment\n",
    "        experiments = df[\"experiment\"].unique()\n",
    "        train_exps, test_exps = train_test_split(\n",
    "            experiments, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        if train:\n",
    "            self.df = df[df[\"experiment\"].isin(train_exps)].reset_index(drop=True)\n",
    "        else:\n",
    "            self.df = df[df[\"experiment\"].isin(test_exps)].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row[\"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "        x, y, w, h = int(row[\"x\"]), int(row[\"y\"]), int(row[\"w\"]), int(row[\"h\"])\n",
    "        bbox = torch.tensor([int(x - w/2), int(y - h/2), int(x + w/2), int(y + h/2)])\n",
    "        image_tensor = T.ToTensor()(image).unsqueeze(0)\n",
    "        cropped = self.crop_and_pad(image=image_tensor, bbox=bbox, output_size=(224, 224)).squeeze(0)\n",
    "\n",
    "\n",
    "        label = int(row[\"id\"])\n",
    "        return cropped, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def crop_and_pad(self, image, bbox, output_size=(224, 224)):\n",
    "        x1, y1, x2, y2 = [max(0, val) for val in bbox.squeeze().int().tolist()]\n",
    "        \n",
    "        cropped = image[:, :, y1:y2, x1:x2] \n",
    "\n",
    "        h, w = cropped.shape[2:]\n",
    "\n",
    "        # Determine padding to make it square\n",
    "        if h > w:\n",
    "            padding = (h - w) // 2\n",
    "            padding_dims = (padding, h - w - padding, 0, 0)  # Pad left/right equally, no padding for top/bottom\n",
    "        else:\n",
    "            padding = (w - h) // 2\n",
    "            padding_dims = (0, 0, padding, w - h - padding)  # Pad top/bottom equally, no padding for left/right\n",
    "\n",
    "        padded_square = Func.pad(cropped, padding_dims, value=0)\n",
    "\n",
    "        resize_transform = Resize(output_size)\n",
    "        resized = resize_transform(padded_square)\n",
    "\n",
    "        return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device('cuda' if args.gpus[0] >= 0 else 'cpu')\n",
    "\n",
    "print('Setting up data...')\n",
    "\n",
    "data_path = os.path.join(args.data_path, args.experiment, args.group)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dset_val = IDDataset(data_path, args.experiment + \"_\" + args.group + \".txt\", train=False, transform=transform, test_size=0.2, unknown_prop=1, random_state=64)\n",
    "print(\"datasets loaded\")\n",
    "\n",
    "val_loader = DataLoader(dset_val, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=4)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
